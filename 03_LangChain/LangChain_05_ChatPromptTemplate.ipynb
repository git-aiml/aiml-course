{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9094617",
   "metadata": {},
   "source": [
    "# Chat Prompt Templates and Chat Prompt Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c937ff57-4974-461b-9cfd-32957cf21736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the line of code below to check the version of langchain in the current environment.\n",
    "# Substitute \"langchain\" with any other package name to check their version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40720295-6930-473f-a9a4-1c740a0865f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 1.0.5\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://docs.langchain.com/\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/anaconda3/envs/LangChain_course_env/lib/python3.13/site-packages\n",
      "Requires: langchain-core, langgraph, pydantic\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6771a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import sks_config\n",
    "#print(sks_config.SKS_OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "952f6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain_core.prompts.chat import (SystemMessagePromptTemplate,\n",
    "                                         HumanMessagePromptTemplate,\n",
    "                                         ChatPromptTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "866442fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/LangChain_course_env/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3639: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(api_key = sks_config.SKS_OPENAI_API_KEY,\n",
    "                  model_name = 'gpt-4', \n",
    "                  model_kwargs = {'seed':365},\n",
    "                  temperature = 0,\n",
    "                  max_tokens = 100\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ed3798",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_S = '{description}'\n",
    "TEMPLATE_H = '''I've recently adopted a {pet}. \n",
    "Could you suggest some {pet} names?'''\n",
    "\n",
    "message_template_s = SystemMessagePromptTemplate.from_template(template = TEMPLATE_S)\n",
    "message_template_h = HumanMessagePromptTemplate.from_template(template = TEMPLATE_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec4dd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pet'], input_types={}, partial_variables={}, template=\"I've recently adopted a {pet}. \\nCould you suggest some {pet} names?\"), additional_kwargs={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_template_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe00128",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([message_template_s, message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93b7ed5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['description', 'pet'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description'], input_types={}, partial_variables={}, template='{description}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pet'], input_types={}, partial_variables={}, template=\"I've recently adopted a {pet}. \\nCould you suggest some {pet} names?\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f223da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_value = chat_template.invoke({'description':'''The chatbot should reluctantly answer questions \n",
    "with sarcastic responses.''', \n",
    "                                   'pet':'''dog'''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "245427d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='The chatbot should reluctantly answer questions \\nwith sarcastic responses.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I've recently adopted a dog. \\nCould you suggest some dog names?\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5d033c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke(chat_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c10de393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Oh, absolutely. Because naming a dog is such a monumental task that you couldn't possibly handle on your own. How about something super original like Fido, Spot, or Rover? Or if you're feeling really adventurous, you could go with Dog. That's sure to turn heads at the dog park.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 39, 'total_tokens': 101, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CbWr4PT6WDsXG5tdRNxqQxpBn3d1y', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--11787269-7623-4af4-84f9-738e4e46d0d7-0', usage_metadata={'input_tokens': 39, 'output_tokens': 62, 'total_tokens': 101, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b59a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fce710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c46aa7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
