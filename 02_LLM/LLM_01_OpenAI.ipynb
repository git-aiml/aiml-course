{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5407691a-8172-42bb-a563-a5da90b02c78",
   "metadata": {},
   "source": [
    "# Setting up the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208fac9c-2693-4d2e-be91-164731c9a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import sks_config\n",
    "#print(sks_config.SKS_OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca562d62-426e-43d4-ada6-9140549f347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a38a94f1-7d38-49e0-b16e-17002b4a86fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key = sks_config.SKS_OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35977eb8-179a-4443-b97e-5fafa5eca9a2",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac407885-cd4a-47a5-af82-cbfa070842ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt: str, max_tokens: int=40) -> str:\n",
    "    \"\"\"\n",
    "    Sends a prompt to GPT-5-nano via the Responses API\n",
    "    and returns the generated text with safe extraction.\n",
    "    \"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        input=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        #temperature=0.7, # degree of randomness, not supported by nono model\n",
    "        max_output_tokens=max_tokens, # This sets the output token limit\n",
    "        reasoning={\"effort\": \"minimal\"} # Sets reasoning to minimal, to reduce model's internal \"reasoning tokens\"  \n",
    "    )\n",
    "    print(\"Model Used:\", response.model)\n",
    "    #print(\"Raw Response:\", response)\n",
    "    #print(\"output_text:\", response.output_text)\n",
    "    #print(\"output:\", response.output)\n",
    "    #print(\"choices:\", getattr(response, \"choices\", None))\n",
    "    \n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "776c746b-050b-48a1-bd5d-2bf345b55c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Used: gpt-5-nano-2025-08-07\n",
      "Model Response: Once upon a time there was a quiet village tucked between emerald hills and a winding river. In that village lived a clockmaker named Mira, who could hear the heart\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "prompt = \"Once upon a time\"\n",
    "generated_text = generate_text(prompt, 50)\n",
    "print(\"Model Response:\", generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b505d68a-e16b-4d14-ace8-7b6b462b9014",
   "metadata": {},
   "source": [
    "# Poetic Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c764ee61-a118-42bd-96dc-0634caf20971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poetic_chatbot(prompt):\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"You are a poetic chatbot\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": \"When was Google founded?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\", \n",
    "                \"content\": \"In the late '90s, a spark did ignite, Google emerged, a radiant light. By Larry and Sergey, in '98, it was born, a search engine new, on the web it was sworn.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Which country has the youngest president?\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Ah, the pursuit of youth in politics, a theme we explore. In Austria, Sebastian Kurz did implore, at the age of 31, his journey did begin, leading with vigor, in a world filled with din.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_output_tokens=256, # This sets the output token limit,\n",
    "        reasoning={\"effort\": \"minimal\"} # Sets reasoning to minimal, to reduce model's internal \"reasoning tokens\"  \n",
    "    )\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01ec835f-66d1-450d-8682-b050b00547db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cheese-making likely began thousands of years ago, with the earliest archaeological hints and legends pointing to the Bronze Age in the Middle East and Europe. Here’s a concise timeline:\\n\\n- Oldest hints: Some traders and herders in the 6th–5th millennia BCE may have stumbled upon curdling milk accidentally while transporting in animal skins, leading to early improvised cheese.\\n- Written/ archaeological clues: By around 5500–3500 BCE, ancient Mesopotamian and Egyptian artifacts suggest dairy processing, including curds and whey, and there are references to cheese-like products in later Mesopotamian tablets and Egyptian tombs.\\n- Classical references: By ancient Greece and Rome (roughly 1st millennium BCE), cheese-making was well established and diversified into many regional varieties.\\n\\nSo, while we can’t pin a single exact year, cheese likely originated several millennia ago, with robust practice by the Bronze Age and beyond.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"When was cheese first made?\"\n",
    "poetic_chatbot(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "511e53d7-ca9e-4c55-93dc-87673cb66d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don’t have real-time access to 365DataScience’s internal release schedule. To find the next course you can:\\n\\n- Check 365DataScience’s website: look for “Upcoming Courses” or their blog/news section.\\n- Follow their social media or newsletter for announcements.\\n- If you have an account, check the dashboard or course catalog for release dates.\\n- Contact their support or sales team for the latest schedule.\\n\\nIf you’d like, tell me what topics you’re hoping to learn (e.g., SQL, Python for data, statistics), and I can suggest related courses that are commonly offered or in-demand.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is the next course to be uploaded to 365DataScience?\"\n",
    "poetic_chatbot(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2302f72-f717-40ba-9e57-402f45265560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_course_env",
   "language": "python",
   "name": "llm_course_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
